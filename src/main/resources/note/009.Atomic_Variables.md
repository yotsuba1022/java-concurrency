# Atomic Variables

* The intrinsic locks that are associated with object monitors have historically suffered
  from poor performance. Although performance has improved, they still present a
  bottleneck when creating web servers and other applications that require high scalability
  and performance in the presence of significant thread contention.

* A lot of research has gone into creating nonblocking algorithms that can radically
  improve performance in synchronization contexts. These algorithms offer increased
  scalability because threads don't block when multiple threads contend for the same data.
  Also, threads don’t suffer from deadlock and other liveness problems.

* Java 5 provided the ability to create efficient nonblocking algorithms by introducing
  the java.util.concurrent.atomic package. According to this package's JDK
  documentation, java.util.concurrent.atomic provides a small toolkit of classes that
  support lock-free, thread-safe operations on single variables.

* The classes in the java.util.concurrent.atomic package extend the notion of
  volatile values, fields, and array elements to those that also provide an atomic
  conditional update so that external synchronization isn't required. In other words, you
  get mutual exclusion along with the memory semantics associated with volatile
  variables without external synchronization.

* Some of the classes located in java.util.concurrent.atomic are described here:
    * AtomicBoolean
    * AtomicInteger
    * AtomicIntegerArray
    * AtomicLong
    * AtomicLongArray
    * AtomicReference
    * AtomicReferenceArray
    * DoubleAccumulator
    * DoubleAdder
    * LongAccumulator
    * LongAdder

* Atomic variables are used to implement:
    * counters
    * sequence generators (such as java.util.concurrent.ThreadLocalRandom)
    * other constructs that require mutual exclusion without performance problems
      under high thread contention

* Understanding the Atomic Magic
    * Java's low-level synchronization mechanism, which enforces the following two things:
        * **Mutual exclusion**: The thread holding the lock that guards a set of variables
          has exclusive access to them

        * **Visibility**: Changes to the guarded variables become visible to other threads
          that subsequently acquire the lock

    * These two points impacts hardware utilization and scalability in the following ways:
        * Contended synchronization (multiple threads constantly
          competing for a lock) is expensive and throughput suffers as a
          result. This expense is caused mainly by the frequent context
          switching (switching the central processing unit from one thread to
          another) that occurs. Each context switch operation can take many
          processor cycles to complete. In contrast, modern Java virtual
          machines (JVMs) make uncontended synchronization inexpensive.

        * When a thread holding a lock is delayed (because of a scheduling
          delay, for example), no thread that requires that lock makes any
          progress; the hardware isn't utilized as well as it might be.

    * Although you might believe that you can use volatile as a synchronization
      alternative, this won't work. **Volatile variables only solve the visibility problem. They
      cannot be used to safely implement the atomic read-modify-write sequences that are
      necessary for implementing thread-safe counters and other entities that require mutual
      exclusion.** However, there is an alternative that's responsible for the performance gains
      offered by the concurrency utilities (such as the java.util.concurrent.Semaphore
      class). This alternative is known as compare-and-swap.

    * Compare-and-swap (CAS) is the generic term for an uninterruptible microprocessorspecific
      instruction that reads a memory location, compares the read value with an
      expected value, and stores a new value in the memory location when the read value
      matches the expected value. Otherwise, nothing is done.

      * CAS supports atomic read-modify-write sequences. You typically use CAS as follows:
        1. Read value x from address A.
        2. Perform a multistep computation on x to derive a new value called y.
        3. Use CAS to change the value of A from x to y. CAS succeeds when A's value hasn't
           changed while performing these steps.

      * CAS is a type of optimistic lock, when there are bunch of threads trying to update the same
        variable via CAS, only one of the thread can success and the others will failed. However,
        those failed threads will not be hanged up but be noticed that it failed in this turn and
        can retry next time.


* Reference:
    * [Java多執行緒: CAS與AtomicInteger (樂觀鎖)](https://github.com/pzxwhc/MineKnowContainer/issues/17)

